{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "973d476f-da88-4847-8b0d-8e495d77993f",
   "metadata": {},
   "source": [
    "# Generate Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d762ca93-e6d8-4b1d-883b-d42b6ee45721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import model\n",
    "from pprint import pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7dd184b-b113-42fe-b10e-8c4ceb21c337",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_fn = model.DefaultEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75c86b7a-7873-47d4-907e-0fbe1aeab1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "import os\n",
    "\n",
    "client = MilvusClient(uri=os.getenv('MILVUS_ADDR'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de8730-1b31-492b-b8fa-78c0e47ca82a",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "591f24b5-c7ce-4083-a3c8-880fb76542c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, collection, threshold=0.5, limit=3):\n",
    "    query_vectors = embedding_fn.encode_queries([query])\n",
    "    results = client.search(\n",
    "        collection_name=collection,  # target collection\n",
    "        data=query_vectors,  # query vectors\n",
    "        limit=limit,  # number of returned entities\n",
    "        output_fields=[\"text\", \"metadata\"],  # specifies fields to be returned\n",
    "        # filter=\"subject == 'history'\", # metadata filtering\n",
    "    )[0]\n",
    "    \n",
    "    distanceThreshold = threshold\n",
    "    \n",
    "    return [\n",
    "        result\n",
    "        for result in results if result['distance'] >= distanceThreshold\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb8c6be-5633-41ab-857d-67dcd958b533",
   "metadata": {},
   "source": [
    "# Load PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "620f7a1b-a3a1-44f5-a9c1-bf8f5fd1868b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 68 0 (offset 0)\n",
      "Ignoring wrong pointing object 72 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import FileSystemBlobLoader\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import PyPDFParser\n",
    "\n",
    "loader = GenericLoader(\n",
    "    blob_loader=FileSystemBlobLoader(\n",
    "        path=\"../datasets\",\n",
    "        glob=\"**/*.pdf\",\n",
    "    ),\n",
    "    blob_parser=PyPDFParser(),\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8576b9aa-1f5e-443e-9dee-111c56a3130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8ba567f-6f66-4cd4-8bcc-9fc32277029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200, # Overlap to maintain context between chunks\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c3c96c7-b653-487f-bad6-c370cd9e7d1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_documents(docs)\n",
    "data = []\n",
    "\n",
    "is_debug = False\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    vector = embedding_fn.encode_documents([chunk.page_content])\n",
    "    d = {\n",
    "        \"id\": i,\n",
    "        \"vector\": vector[0],\n",
    "        \"text\": chunk.page_content,\n",
    "        \"metadata\": chunk.metadata,\n",
    "    }\n",
    "    data.append(d)\n",
    "    is_debug and print(i)\n",
    "    is_debug and print(chunk.page_content)\n",
    "    is_debug and pp(chunk.metadata)\n",
    "    is_debug and print('=====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e931d1a9-0158-4ce9-8496-90c3ce32da78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pdf_collection']\n"
     ]
    }
   ],
   "source": [
    "client.has_collection(collection_name=\"pdf_collection\") and client.drop_collection(collection_name=\"pdf_collection\")\n",
    "client.create_collection(\n",
    "    collection_name=\"pdf_collection\",\n",
    "    dimension=embedding_fn.dim, \n",
    ")\n",
    "pp(client.list_collections())\n",
    "res = client.insert(collection_name=\"pdf_collection\", data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b1c804",
   "metadata": {},
   "source": [
    "# Test Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50190723-5cb6-47d2-8aa7-884183987742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'model_garden'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from llm import ModelGardenLLM\n",
    "from embeddings import ModelGardenEmbeddings, OllamaRagasEmbeddings\n",
    "from langchain_ollama import OllamaLLM, OllamaEmbeddings\n",
    "\n",
    "llm_type = os.getenv('LLM_TYPE')\n",
    "model = os.getenv('MODEL_GARDEN_MODEL')\n",
    "embedding = os.getenv('EMBEDDING_MODEL')\n",
    "\n",
    "if llm_type == \"model_garden\":\n",
    "    url = os.getenv('MODEL_GARDEN_URL')\n",
    "    embed_url = os.getenv('EMBEDDING_URL')\n",
    "    llm = ModelGardenLLM(api_url=url, model=model)\n",
    "    embeds = ModelGardenEmbeddings(api_url=embed_url, model=embedding)\n",
    "elif llm_type == \"ollama\":\n",
    "    llm = OllamaLLM(model=model, temperature=0.4)\n",
    "    embeds = OllamaRagasEmbeddings(model=embedding)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported LLM type: {llm_type}\")\n",
    "pp(llm_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d2018f3-93fc-4ccf-a75e-e27541f4659c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd946d9ae499406cbe0ab4f957463625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c8042d097c438099773fa49beeb3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa34f4ffe3a74115a00464ce14246962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying EmbeddingExtractor:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d211388484a456db7d7be9cf7b6ecef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying ThemesExtractor:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f94709f8c74753bb827a8931b87d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying NERExtractor:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731f882cdd04441dbae664e12285834b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CosineSimilarityBuilder:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7e91dd738a467a982eceac6f51fea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying OverlapScoreBuilder:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cfc161d91ec48e1b69667d9865efae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958ea30c4a2e4ab2aa69ac6f3ffbf252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2cc87fc7eff4e98bcbbb6973efe61c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=llm, embedding_model=embeds)\n",
    "dataset = generator.generate_with_langchain_docs(docs, testset_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e1e9ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>persona_name</th>\n",
       "      <th>query_style</th>\n",
       "      <th>query_length</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Whaat izz BARITO?</td>\n",
       "      <td>[H Ho ow w  w we e  b bu ui il lt t  ‘ ‘B BA A...</td>\n",
       "      <td>We built ‘BARITO’ to enhance logging.</td>\n",
       "      <td>DevOps Engineer - Arya Pratama</td>\n",
       "      <td>MISSPELLED</td>\n",
       "      <td>SHORT</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How did GO-JEK address the increasing complexi...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nH Ho ow w  w we e  b bu ui il lt t...</td>\n",
       "      <td>GO-JEK built ‘BARITO’ to enhance logging, addr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to the provided context, what proble...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nwant answers. So imagine how glad ...</td>\n",
       "      <td>At GO-JEK’s scale, the conventional ELK stack ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0                                  Whaat izz BARITO?   \n",
       "1  How did GO-JEK address the increasing complexi...   \n",
       "2  According to the provided context, what proble...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [H Ho ow w  w we e  b bu ui il lt t  ‘ ‘B BA A...   \n",
       "1  [<1-hop>\\n\\nH Ho ow w  w we e  b bu ui il lt t...   \n",
       "2  [<1-hop>\\n\\nwant answers. So imagine how glad ...   \n",
       "\n",
       "                                           reference  \\\n",
       "0              We built ‘BARITO’ to enhance logging.   \n",
       "1  GO-JEK built ‘BARITO’ to enhance logging, addr...   \n",
       "2  At GO-JEK’s scale, the conventional ELK stack ...   \n",
       "\n",
       "                     persona_name query_style query_length  \\\n",
       "0  DevOps Engineer - Arya Pratama  MISSPELLED        SHORT   \n",
       "1                             NaN         NaN          NaN   \n",
       "2                             NaN         NaN          NaN   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0  single_hop_specific_query_synthesizer  \n",
       "1   multi_hop_abstract_query_synthesizer  \n",
       "2   multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd13981-de96-4d81-b7d1-dedc57a05207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df[['user_input', 'reference_contexts', 'reference']]\n",
    "df_final.to_csv('test_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3c4159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaluator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
