{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "973d476f-da88-4847-8b0d-8e495d77993f",
   "metadata": {},
   "source": [
    "# Generate Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d762ca93-e6d8-4b1d-883b-d42b6ee45721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import model\n",
    "from pprint import pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d957b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7dd184b-b113-42fe-b10e-8c4ceb21c337",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_fn = model.DefaultEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75c86b7a-7873-47d4-907e-0fbe1aeab1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "import os\n",
    "\n",
    "client = MilvusClient(uri=os.getenv('MILVUS_ADDR'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de8730-1b31-492b-b8fa-78c0e47ca82a",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591f24b5-c7ce-4083-a3c8-880fb76542c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, collection, threshold=0.5, limit=3):\n",
    "    query_vectors = embedding_fn.encode_queries([query])\n",
    "    results = client.search(\n",
    "        collection_name=collection,  # target collection\n",
    "        data=query_vectors,  # query vectors\n",
    "        limit=limit,  # number of returned entities\n",
    "        output_fields=[\"text\", \"metadata\"],  # specifies fields to be returned\n",
    "        # filter=\"subject == 'history'\", # metadata filtering\n",
    "    )[0]\n",
    "    \n",
    "    distanceThreshold = threshold\n",
    "    \n",
    "    return [\n",
    "        result\n",
    "        for result in results if result['distance'] >= distanceThreshold\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb8c6be-5633-41ab-857d-67dcd958b533",
   "metadata": {},
   "source": [
    "# Load PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f7a1b-a3a1-44f5-a9c1-bf8f5fd1868b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 68 0 (offset 0)\n",
      "Ignoring wrong pointing object 72 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import FileSystemBlobLoader\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import PyPDFParser\n",
    "\n",
    "loader = GenericLoader(\n",
    "    blob_loader=FileSystemBlobLoader(\n",
    "        path=\"../datasets\",\n",
    "        glob=\"*.pdf\",\n",
    "    ),\n",
    "    blob_parser=PyPDFParser(),\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8576b9aa-1f5e-443e-9dee-111c56a3130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8ba567f-6f66-4cd4-8bcc-9fc32277029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200, # Overlap to maintain context between chunks\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3c96c7-b653-487f-bad6-c370cd9e7d1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_documents(docs)\n",
    "data = []\n",
    "\n",
    "is_debug = False\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    vector = embedding_fn.encode_documents([chunk.page_content])\n",
    "    d = {\n",
    "        \"id\": i,\n",
    "        \"vector\": vector[0],\n",
    "        \"text\": chunk.page_content,\n",
    "        \"metadata\": chunk.metadata,\n",
    "    }\n",
    "    data.append(d)\n",
    "    is_debug and print(i)\n",
    "    is_debug and print(chunk.page_content)\n",
    "    is_debug and pp(chunk.metadata)\n",
    "    is_debug and print('=====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e931d1a9-0158-4ce9-8496-90c3ce32da78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pdf_collection']\n"
     ]
    }
   ],
   "source": [
    "client.has_collection(collection_name=\"pdf_collection\") and client.drop_collection(collection_name=\"pdf_collection\")\n",
    "client.create_collection(\n",
    "    collection_name=\"pdf_collection\",\n",
    "    dimension=embedding_fn.dim, \n",
    ")\n",
    "pp(client.list_collections())\n",
    "res = client.insert(collection_name=\"pdf_collection\", data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b1c804",
   "metadata": {},
   "source": [
    "# Test Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50190723-5cb6-47d2-8aa7-884183987742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm import ModelGardenLLM\n",
    "from embeddings import ModelGardenEmbeddings\n",
    "\n",
    "url = os.getenv('MODEL_GARDEN_URL')\n",
    "model = os.getenv('MODEL_GARDEN_MODEL')\n",
    "embed_url = os.getenv('EMBEDDING_URL')\n",
    "embedding = os.getenv('EMBEDDING_MODEL')\n",
    "\n",
    "llm = ModelGardenLLM(api_url=url, model=model)\n",
    "embeds = ModelGardenEmbeddings(api_url=embed_url, model=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d2018f3-93fc-4ccf-a75e-e27541f4659c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da6ab7cb7bb4f548ae2560637cb8ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac2d0c48c6943dc8d8933c75823d0ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ec54d621f14813bf3eb372990992b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying EmbeddingExtractor:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6507670f5d4a47759f043353fd710e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying ThemesExtractor:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fff493628d14b6aa078e75f07b264a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying NERExtractor:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f6e414419e4d49a4188817f36232b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CosineSimilarityBuilder:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020877be2e6c4c6990a75218d824559d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying OverlapScoreBuilder:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad85c0a2770941d7ab6586d9aeaaf760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ef2f5411444ad8aa3b05327849e42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed0f97867084fbc8349cddca547cf1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=llm, embedding_model=embeds)\n",
    "dataset = generator.generate_with_langchain_docs(docs, testset_size=1)\n",
    "dataset.to_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97e90375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>persona_name</th>\n",
       "      <th>query_style</th>\n",
       "      <th>query_length</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to the provided text, what was the p...</td>\n",
       "      <td>[H Ho ow w  w we e  b bu ui il lt t  ‘ ‘B BA A...</td>\n",
       "      <td>‘BARITO’ was built to enhance logging.</td>\n",
       "      <td>DevOps Engineer - GO-JEK</td>\n",
       "      <td>PERFECT_GRAMMAR</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>single_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logging infrastructure at GO-JEK, like, why is...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nwant answers. So imagine how glad ...</td>\n",
       "      <td>Logging is critical at GO-JEK because it provi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to the RedSeer Industry Report relea...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nGoPay, as part of Indonesia’s tech...</td>\n",
       "      <td>According to the RedSeer Industry Report relea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  According to the provided text, what was the p...   \n",
       "1  logging infrastructure at GO-JEK, like, why is...   \n",
       "2  According to the RedSeer Industry Report relea...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [H Ho ow w  w we e  b bu ui il lt t  ‘ ‘B BA A...   \n",
       "1  [<1-hop>\\n\\nwant answers. So imagine how glad ...   \n",
       "2  [<1-hop>\\n\\nGoPay, as part of Indonesia’s tech...   \n",
       "\n",
       "                                           reference  \\\n",
       "0             ‘BARITO’ was built to enhance logging.   \n",
       "1  Logging is critical at GO-JEK because it provi...   \n",
       "2  According to the RedSeer Industry Report relea...   \n",
       "\n",
       "               persona_name      query_style query_length  \\\n",
       "0  DevOps Engineer - GO-JEK  PERFECT_GRAMMAR       MEDIUM   \n",
       "1                       NaN              NaN          NaN   \n",
       "2                       NaN              NaN          NaN   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0  single_hop_specific_query_synthesizer  \n",
       "1   multi_hop_abstract_query_synthesizer  \n",
       "2   multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaluator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
